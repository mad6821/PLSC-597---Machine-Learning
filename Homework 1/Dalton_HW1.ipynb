{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05495f55-90fd-47e0-bc76-e6ce4a22e05d",
   "metadata": {},
   "source": [
    "# PLSC 597 - Homework 1\n",
    "### Maya Dalton (9/11/23)\n",
    "\n",
    "Please find my Jupyter Notebook file and data file for this assignment here: https://github.com/mad6821/PLSC-597---Machine-Learning\n",
    "\n",
    "Bauhr, M., & Charron, N. (2021). Will Women Executives Reduce Corruption? Marginalization \n",
    "and Network Inclusion. Comparative Political Studies, 54(7), 1292–1322. https://doi.org/10.1177/0010414020970218\n",
    "\n",
    "With a wide plethora of research investigating the relationship between women’s representation in government and corruption levels, Bauhr and Charron add to this literature by focusing on (1) local-level representation in the form of female mayors, (2) if women’s representation diminishes corruption levels, and (3) if these effects last over time. The authors utilize a simple OLS regression model, along with a regression discontinuity design and a first-differences design to investigate the direction and magnitude of the relationship between women’s representation and corruption in French municipalities. The authors find that women mayors, in fact, reduce corruption risks, with newly elected female mayors primarily driving this relationship. Interestingly, when women mayors are re-elected, they find negligible differences in corruption levels. The replication archive with the data and code for this article can be found here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/FOSMRN.\n",
    "The authors are very straightforward in their research design goals. They want to uncover causal effects of electing female mayors on corruption risks. To do so, they primarily utilize the regression discontinuity design (RDD), but also employ a simple OLS regression. While there is no discussion of why this OLS regression appears in their results, it seems to be utilized as a baseline or benchmark to compare with the RDD. Overall, their modeling goal is explanatory, as they apply statistical models to data for testing causal hypotheses about theoretical constructs of gender and corruption. They utilize a variety of covariates, such as economic development, population density, voter turnout, wages, number of parties competing in elections, rounds of elections, and incumbency. \n",
    "\n",
    "If I were to propose a change to the regression model, I would remove some additional covariates. Specifically, I would remove the variable controlling for the level of income inequality in the municipality, measured by the wages of an average worker. Additionally, I would remove the control for the number of total and commercial only registered firms in each municipality, as well as the re-election variable. This deicsion is due to the fact that these variables not only are statistically significant, but they also do not have a strong effect on the dependent variable, as shown below in the regression table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5c4c6151-5125-4e6e-a474-46fa6953f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     rev_sb_elec_periodw   R-squared:                       0.020\n",
      "Model:                             OLS   Adj. R-squared:                  0.012\n",
      "Method:                  Least Squares   F-statistic:                     2.419\n",
      "Date:                 Mon, 04 Sep 2023   Prob (F-statistic):            0.00754\n",
      "Time:                         21:07:00   Log-Likelihood:                 45.039\n",
      "No. Observations:                 1195   AIC:                            -68.08\n",
      "Df Residuals:                     1184   BIC:                            -12.13\n",
      "Df Model:                           10                                         \n",
      "Covariance Type:             nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1092      0.093      1.172      0.241      -0.074       0.292\n",
      "fem_win08     -0.0301      0.015     -2.072      0.039      -0.059      -0.002\n",
      "logPopDens     0.0083      0.007      1.278      0.202      -0.004       0.021\n",
      "re_elect       0.0007      0.015      0.048      0.962      -0.029       0.030\n",
      "year           0.0457      0.015      3.137      0.002       0.017       0.074\n",
      "turnout_r1     0.0013      0.001      1.277      0.202      -0.001       0.003\n",
      "rounds         0.0093      0.015      0.620      0.535      -0.020       0.039\n",
      "ave_highEd    -0.0020      0.001     -2.236      0.026      -0.004      -0.000\n",
      "ave_t_wage  5.371e-07   1.29e-05      0.042      0.967   -2.47e-05    2.58e-05\n",
      "no_firms    1.238e-05   1.69e-05      0.732      0.464   -2.08e-05    4.55e-05\n",
      "com_firm    -6.98e-05      0.000     -0.478      0.632      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      360.813   Durbin-Watson:                   2.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              920.134\n",
      "Skew:                           1.601   Prob(JB):                    1.57e-200\n",
      "Kurtosis:                       5.868   Cond. No.                     3.37e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.37e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries, storing as shorthand\n",
    "import numpy as np        #base package \n",
    "import pandas as pd       #working with data frames\n",
    "import matplotlib.pyplot as plt   #plotting library\n",
    "from sklearn.model_selection import train_test_split  #standard machine learning library\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Path to the .dta file\n",
    "file_path = \"/storage/home/mad6821/work/Machine Learning/Homework/Bauhr and Charron CPS data rd estimates.dta\"\n",
    "\n",
    "# Read the .dta file into a pandas DataFrame\n",
    "df = pd.read_stata(file_path)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Fit regression model\n",
    "model = sm.OLS.from_formula(\"rev_sb_elec_periodw ~ fem_win08 + logPopDens + re_elect + year + turnout_r1 + rounds + ave_highEd + ave_t_wage + no_firms + com_firm\", data=df)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd2961-4d17-4d13-a9bb-62b182d7797c",
   "metadata": {},
   "source": [
    "Therefore, I will present an assessment of the out-of-sample predictive performance of the same model as Bauhr and Charron's model, with income inequality (wages) removed performs better than that of the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a0331f7d-b197-4017-98dd-cd5c87b6390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with original mode: 0.05949942073067781\n",
      "MSE with removed covariates: 0.05940828578882852\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=1234)\n",
    "\n",
    "# Independent variables\n",
    "independent_vars = ['fem_win08', 'logPopDens', 'year', 'turnout_r1', 'rounds', 'ave_highEd']\n",
    "covariates = ['ave_t_wage'] + ['no_firms'] + ['com_firm'] + ['re_elect']\n",
    "\n",
    "# Model with all covariates\n",
    "X_train_original = train_data[independent_vars + covariates]\n",
    "Y_train = train_data['rev_sb_elec_periodw']\n",
    "\n",
    "model_original = LinearRegression().fit(X_train_original, Y_train)\n",
    "\n",
    "X_test_original = test_data[independent_vars + covariates]\n",
    "Y_test = test_data['rev_sb_elec_periodw']\n",
    "\n",
    "predictions_original = model_original.predict(X_test_original)\n",
    "mse_original = mean_squared_error(Y_test, predictions_original)\n",
    "\n",
    "# Model without covariates\n",
    "X_train_alt = train_data[independent_vars]\n",
    "\n",
    "model_alt = LinearRegression().fit(X_train_alt, Y_train)\n",
    "\n",
    "X_test_alt = test_data[independent_vars]\n",
    "\n",
    "predictions_alt = model_alt.predict(X_test_alt)\n",
    "mse_alt = mean_squared_error(Y_test, predictions_alt)\n",
    "\n",
    "# Compare the MSE values\n",
    "print(\"MSE with original mode:\", mse_original)\n",
    "print(\"MSE with removed covariates:\", mse_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335bd1b-1573-45ec-903e-723bdc87179b",
   "metadata": {},
   "source": [
    "As shown above, the mean squared error after removing covariates is smaller than the mean squared error of the original model. This shows that throwing in covariates for any potential cofounder is not always a good decision when deciding on a statistical model in our research. Wages as a measure of income inequality, the total number of firms, the number of commericial only firms, and a re-election variable did not provide much to the original regression model, and were not statistically significant, therefore the predicitive performance of a model without them is stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e9507-5725-4b8a-82b2-15e56a06ba46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
